{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliah\\AppData\\Local\\Temp\\ipykernel_1724\\4145169654.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eliah\\Documents\\Master\\Eliah-Masters\\Pipelines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Data_Feature')\n",
    "sys.path.append('../Data_processing')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, make_scorer, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_processing import KOProcessor, TraitManager  # Assuming your data processing script is saved as 'data_processing.py'\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from bioservices import KEGG\n",
    "import multiprocessing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "   Unnamed: 0   key      KO\n",
      "0           0  1000  K00001\n",
      "1           1  1000  K13954\n",
      "2           2  1000  K00003\n",
      "3           3  1000  K00013\n",
      "4           4  1000  K00014\n",
      "Data loaded successfully:\n",
      "   key        ID                      speciesStrain  \\\n",
      "0    1  592010.0   Abiotrophia defectiva ATCC 49176   \n",
      "1    1     219.0     Abiotrophia defectiva DSM 9849   \n",
      "2    2  159837.0       Abyssibacter profundi OUC007   \n",
      "3    3       NaN  Acanthopleuribacter pedis FYK2218   \n",
      "4    4  258515.0   Acetanaerobacterium elongatum Z7   \n",
      "\n",
      "                 speciesStrainComp                genus            genusComp  \\\n",
      "0    abiotrophiadefectivaatcc49176          Abiotrophia          abiotrophia   \n",
      "1      abiotrophiadefectivadsm9849          Abiotrophia          abiotrophia   \n",
      "2       abyssibacterprofundiouc007         Abyssibacter         abyssibacter   \n",
      "3  acanthopleuribacterpedisfyk2218  Acanthopleuribacter  acanthopleuribacter   \n",
      "4   acetanaerobacteriumelongatumz7  Acetanaerobacterium  acetanaerobacterium   \n",
      "\n",
      "                         species                   speciesComp      strain  \\\n",
      "0          Abiotrophia defectiva          abiotrophiadefectiva  ATCC 49176   \n",
      "1          Abiotrophia defectiva          abiotrophiadefectiva    DSM 9849   \n",
      "2          Abyssibacter profundi          abyssibacterprofundi      OUC007   \n",
      "3      Acanthopleuribacter pedis      acanthopleuribacterpedis     FYK2218   \n",
      "4  Acetanaerobacterium elongatum  acetanaerobacteriumelongatum          Z7   \n",
      "\n",
      "                              cultureNo typeStrain misclassified      gram  \\\n",
      "0                                   NaN        NaN           NaN  positive   \n",
      "1  DSM 9849|ATCC 49176|CIP 103242|SC 10        yes           NaN       NaN   \n",
      "2     KCTC 52933|MCCC 1K03450|JCM 32025        yes           NaN       NaN   \n",
      "3                                   NaN        NaN           NaN  negative   \n",
      "4                                   NaN        NaN           NaN  positive   \n",
      "\n",
      "        oxygen                                          substrate  \\\n",
      "0  facultative                                                NaN   \n",
      "1    anaerobic  alpha-cyclodextrin|arginine|D-arabitol|D-manni...   \n",
      "2      aerobic  2-oxopentanoate|4-hydroxybutyrate|adipate|algi...   \n",
      "3      aerobic  adipate|alanine|arginine|decanoate|D-glucose|D...   \n",
      "4    anaerobic  arabinose|cellobiose|esculin|fructose|galactos...   \n",
      "\n",
      "                                         genomeAccNo      usedAccNo  \\\n",
      "0  GCA_000160075|GCA_013267415|46125.34|46125.35|...  GCA_000160075   \n",
      "1  GCA_000160075|GCA_013267415|46125.34|46125.35|...  GCA_000160075   \n",
      "2    GCA_003151135|2831460164|QEQK00000000|2182787.3  GCA_003151135   \n",
      "3                             GCA_017377855|442870.4  GCA_017377855   \n",
      "4                 258515.18|GCA_900103835|2667527408  GCA_900103835   \n",
      "\n",
      "                                         ncbiFTP_FAA  \n",
      "0  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/0...  \n",
      "1  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/0...  \n",
      "2  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/0...  \n",
      "3  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/0...  \n",
      "4  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/9...  \n",
      "Error: Missing columns ['speciesstrain', 'speciesstraincomp'] in the reduced traits data.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m y_traits \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mpreprocess_traits(reduced_traits_data, trait_column\u001b[38;5;241m=\u001b[39mtrait_column, use_assembled_if_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Align features and labels\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m X_aligned, Y_aligned \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_terms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_traits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Feature Selection: Variance Threshold\u001b[39;00m\n\u001b[0;32m     30\u001b[0m selector \u001b[38;5;241m=\u001b[39m VarianceThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.04\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eliah\\Documents\\Master\\Eliah-Masters\\Pipelines\\../Data_processing\\data_processing.py:154\u001b[0m, in \u001b[0;36mDataProcessor.align_data\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malign_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Aligns features and labels based on common keys.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     common_keys \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mintersection(\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m)\n\u001b[0;32m    155\u001b[0m     X_aligned \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[common_keys]\n\u001b[0;32m    156\u001b[0m     y_aligned \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mloc[common_keys]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "terms_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/terms_KO.zip'\n",
    "terms_csv_path = 'terms_KO.csv'\n",
    "traits_reduced_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/reducedDataset.zip'\n",
    "traits_reduced_csv_path = 'reducedDataset.csv'\n",
    "traits_assembled_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/assembledDataset.zip'\n",
    "traits_assembled_csv_path = 'assembledDataset.csv'\n",
    "\n",
    "processor = KOProcessor(\n",
    "    terms_zip_path, \n",
    "    terms_csv_path, \n",
    "    traits_reduced_zip_path, \n",
    "    traits_reduced_csv_path, \n",
    "    traits_assembled_zip_path=traits_assembled_zip_path, \n",
    "    traits_assembled_csv_path=traits_assembled_csv_path\n",
    ")\n",
    "\n",
    "# Load and preprocess KO terms and traits\n",
    "trait_column = 'gram'\n",
    "ko_terms = processor.load_terms()\n",
    "reduced_traits_data = processor.load_reduced_traits_data()\n",
    "\n",
    "X_terms = processor.preprocess_terms(ko_terms)\n",
    "y_traits = processor.preprocess_traits(reduced_traits_data, trait_column=trait_column, use_assembled_if_missing=True)\n",
    "\n",
    "# Align features and labels\n",
    "X_aligned, Y_aligned = processor.align_data(X_terms, y_traits)\n",
    "\n",
    "# Feature Selection: Variance Threshold\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_aligned = selector.fit_transform(X_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated train_and_evaluate function using Leave-One-Out Cross-Validation\n",
    "def train_and_evaluate(X_aligned, Y_aligned):\n",
    "    results = {}\n",
    "    print(f\"Processing trait: {trait_column}\")\n",
    "    \n",
    "    # Binary labels for the current trait\n",
    "    Y_current = Y_aligned.values.flatten()\n",
    "    \n",
    "    # Define a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('select_k', SelectKBest(f_classif)),\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('estimator', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define a parameter grid to search over\n",
    "    param_grid = [\n",
    "        {\n",
    "            'select_k__k': [10, 100, 1000],\n",
    "            'estimator': [RandomForestClassifier(random_state=42)],\n",
    "            'estimator__n_estimators': [100, 200],\n",
    "            'estimator__max_depth': [5, 10, None]\n",
    "        },\n",
    "        {\n",
    "            'select_k__k': [10, 100, 1000],\n",
    "            'estimator': [SVC(random_state=42)],\n",
    "            'estimator__C': [0.1, 1, 10],\n",
    "            'estimator__kernel': ['linear', 'rbf'],\n",
    "            'estimator__gamma': ['scale', 'auto']\n",
    "        },\n",
    "        {\n",
    "            'select_k__k': [10, 100, 1000],\n",
    "            'estimator': [LogisticRegression(max_iter=1000)],\n",
    "            'estimator__C': [0.01, 0.1, 1, 10, 100]\n",
    "        },\n",
    "        {\n",
    "            'select_k__k': [10, 100, 1000],\n",
    "            'estimator': [BernoulliNB()],\n",
    "            'estimator__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "            'estimator__binarize': [0.0]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Grid search with Leave-One-Out cross-validation using multiple CPU cores\n",
    "    loo = LeaveOneOut()\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=loo, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_aligned, Y_current)\n",
    "\n",
    "    print(f\"Best parameters found for {trait_column}:\", grid_search.best_params_)\n",
    "    print(f\"Best cross-validation score for {trait_column}: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Use cross_val_predict to get predictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    Y_pred = cross_val_predict(best_model, X_aligned, Y_current, cv=loo, n_jobs=-1)\n",
    "\n",
    "    mcc = matthews_corrcoef(Y_current, Y_pred)\n",
    "    print(f\"Matthews Correlation Coefficient for {trait_column}: {mcc:.3f}\")\n",
    "\n",
    "    # Display confusion matrix\n",
    "    cm = confusion_matrix(Y_current, Y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion Matrix for {trait_column} Classifier')\n",
    "    plt.show()\n",
    "    \n",
    "    # Store results\n",
    "    results[trait_column] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'mcc': mcc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "    # Print final results\n",
    "    print(f\"Trait: {trait_column}\")\n",
    "    print(f\"Best Parameters: {results[trait_column]['best_params']}\")\n",
    "    print(f\"Best Cross-Validation Score: {results[trait_column]['best_score']:.3f}\")\n",
    "    print(f\"MCC: {results[trait_column]['mcc']:.3f}\")\n",
    "    print(f\"Confusion Matrix:\\n{results[trait_column]['confusion_matrix']}\\n\")\n",
    "\n",
    "    # F1 Score vs. MCC Graph\n",
    "    f1 = f1_score(Y_current, Y_pred, average='macro')\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(['F1 Score', 'MCC'], [f1, mcc], color=['blue', 'green'])\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('F1 Score vs. MCC')\n",
    "    plt.show()\n",
    "\n",
    "# Run the function with your data\n",
    "train_and_evaluate(X_aligned, Y_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEGG Pathway Mapping\n",
    "def map_ko_to_pathways(ko_terms):\n",
    "    kegg = KEGG()\n",
    "    pathways = {}\n",
    "    for ko in ko_terms:\n",
    "        try:\n",
    "            gene_links = kegg.link(\"pathway\", ko)\n",
    "            if gene_links:\n",
    "                for entry in gene_links.strip().split(\"\\n\"):\n",
    "                    split_entry = entry.split(\"\\t\")\n",
    "                    if len(split_entry) >= 2:\n",
    "                        ko_id, pathway_id = split_entry[0], split_entry[1]\n",
    "                        if pathway_id not in pathways:\n",
    "                            pathways[pathway_id] = set()\n",
    "                        pathways[pathway_id].add(ko)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ko}: {e}\")\n",
    "    return pathways\n",
    "\n",
    "selected_important_features = X_terms.columns[selector.get_support()]\n",
    "pathways = map_ko_to_pathways(selected_important_features)\n",
    "\n",
    "# Creating the adjacency matrix with translated KO terms, including original KO term\n",
    "translated_kos = {ko: f\"Translated_{ko}\" for ko in selected_important_features}  # Placeholder for actual translation function\n",
    "pathway_matrix = pd.DataFrame(\n",
    "    index=[f\"{translated_kos[ko]} ({ko})\" for ko in selected_important_features],\n",
    "    columns=pathways.keys(),\n",
    "    data=0\n",
    ")\n",
    "for pathway, kos in pathways.items():\n",
    "    for ko in kos:\n",
    "        if ko in selected_important_features:\n",
    "            pathway_matrix.loc[f\"{translated_kos[ko]} ({ko})\", pathway] = 1\n",
    "\n",
    "# Fetch and rename pathway names for readability\n",
    "kegg = KEGG()\n",
    "for column in pathway_matrix.columns:\n",
    "    pathway_info = kegg.get(column)\n",
    "    parsed_info = kegg.parse(pathway_info)\n",
    "    pathway_name = parsed_info['NAME'][0] if 'NAME' in parsed_info else column\n",
    "    pathway_matrix.rename(columns={column: pathway_name}, inplace=True)\n",
    "\n",
    "print(\"Pathway matrix after renaming:\\n\", pathway_matrix)\n",
    "\n",
    "# Heatmap visualization\n",
    "sns.heatmap(pathway_matrix, annot=True, cmap=\"Greys\", cbar=False)\n",
    "plt.title(f'Adjacency Matrix of KO Terms and Pathways ({trait_column})')\n",
    "plt.xlabel('Pathways')\n",
    "plt.ylabel('KO Terms')\n",
    "plt.show()\n",
    "\n",
    "# Network Visualization\n",
    "G = nx.Graph()\n",
    "\n",
    "# Define a list of general pathways to exclude\n",
    "excluded_pathways = [\"metabolic pathways\"]  # You can add more general terms here\n",
    "\n",
    "# Add nodes and edges with renamed pathway names\n",
    "for ko in selected_important_features:\n",
    "    translated_label = f\"{translated_kos[ko]} ({ko})\"\n",
    "    G.add_node(ko, title=translated_label, label=translated_label, color='red', size=20)\n",
    "\n",
    "for pathway_id, kos in pathways.items():\n",
    "    pathway_info = kegg.get(pathway_id)\n",
    "    parsed_info = kegg.parse(pathway_info)\n",
    "    pathway_name = parsed_info['NAME'][0] if 'NAME' in parsed_info else pathway_id\n",
    "    if pathway_name.lower() not in excluded_pathways:\n",
    "        G.add_node(pathway_name, title=pathway_name, label=pathway_name, color='blue', size=30)\n",
    "        for ko in kos:\n",
    "            G.add_edge(ko, pathway_name)\n",
    "\n",
    "# Pyvis network visualization\n",
    "nt = Network(\"800px\", \"1200px\", notebook=True, heading=f'Interactive Network of KO Terms and Pathways ({trait_column})', bgcolor=\"#ffffff\", font_color=\"black\", cdn_resources='remote')\n",
    "nt.from_nx(G)\n",
    "nt.toggle_physics(True)\n",
    "nt.show_buttons(filter_=['physics'])\n",
    "nt.save_graph(f\"ko_network_{trait_column}.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
