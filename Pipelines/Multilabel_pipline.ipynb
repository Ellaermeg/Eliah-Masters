{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eliah\\Documents\\Master\\Eliah-Masters\\Pipelines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Data_Feature')\n",
    "sys.path.append('../Data_processing')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, precision_recall_curve, brier_score_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_processing import KOProcessor \n",
    "import logging\n",
    "import warnings\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy import interpolate\n",
    "from itertools import cycle\n",
    "# Add these to your existing imports:\n",
    "from scipy.stats import entropy\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {  \n",
    "        'estimator': [MultiOutputClassifier(RandomForestClassifier(random_state=42))],\n",
    "        'estimator__estimator__n_estimators': [100, 200, 300],  \n",
    "        'estimator__estimator__max_depth': [5, 10, 15, None]  \n",
    "    },\n",
    "    {  \n",
    "        'estimator': [MultiOutputClassifier(SVC(random_state=42, probability=True))],  # Added probability\n",
    "        'estimator__estimator__C': [0.1, 1, 10],  \n",
    "        'estimator__estimator__kernel': ['linear', 'rbf'], \n",
    "        'estimator__estimator__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    {\n",
    "        'estimator': [MultiOutputClassifier(LogisticRegression())],\n",
    "        'estimator__estimator__C': [0.01, 0.1, 1, 10, 100]\n",
    "    }         \n",
    "]\n",
    "\n",
    "target_traits = ['gram', 'oxygen']  # Add/remove traits as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "terms_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/terms_KO.zip'\n",
    "terms_csv_path = 'terms_KO.csv'\n",
    "traits_reduced_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/reducedDataset.zip'\n",
    "traits_reduced_csv_path = 'reducedDataset.csv'\n",
    "traits_assembled_zip_path = 'C:/Users/eliah/Documents/Master/Eliah-Masters/Datasets/assembledDataset.zip'\n",
    "traits_assembled_csv_path = 'assembledDataset.csv'\n",
    "\n",
    "processor = KOProcessor(\n",
    "    terms_zip_path, \n",
    "    terms_csv_path, \n",
    "    traits_reduced_zip_path, \n",
    "    traits_reduced_csv_path, \n",
    "    traits_assembled_zip_path=traits_assembled_zip_path, \n",
    "    traits_assembled_csv_path=traits_assembled_csv_path\n",
    ")\n",
    "\n",
    "ko_terms = processor.load_terms()\n",
    "if ko_terms is None:\n",
    "    raise FileNotFoundError(\"KO terms could not be loaded. Please check the file paths.\")\n",
    "\n",
    "reduced_traits_data = processor.load_reduced_traits_data()\n",
    "if reduced_traits_data is None:\n",
    "    raise FileNotFoundError(\"Reduced traits data could not be loaded. Please check the file paths.\")\n",
    "\n",
    "# Preprocess KO terms\n",
    "X_terms = processor.preprocess_terms(ko_terms)\n",
    "\n",
    "# Preprocess all target traits into a DataFrame\n",
    "y_dfs = []\n",
    "label_encoders = {}  # Store encoders for each trait\n",
    "\n",
    "for trait in target_traits:\n",
    "    y_trait = processor.preprocess_traits(reduced_traits_data, trait_column=trait, use_assembled_if_missing=True)\n",
    "    if y_trait is not None:\n",
    "        # Encode labels to numerical values\n",
    "        le = LabelEncoder()\n",
    "        encoded = le.fit_transform(y_trait)\n",
    "        y_dfs.append(pd.Series(encoded, index=y_trait.index, name=trait))\n",
    "        label_encoders[trait] = le\n",
    "\n",
    "y_combined = pd.concat(y_dfs, axis=1).dropna()\n",
    "\n",
    "# Align features with labels\n",
    "X_aligned, Y_aligned = processor.align_data(X_terms, y_combined)\n",
    "\n",
    "# Feature Selection: Variance Threshold\n",
    "selector = VarianceThreshold(threshold=0.03)\n",
    "X_aligned = selector.fit_transform(X_aligned)\n",
    "\n",
    "# Check trait distributions\n",
    "for trait in target_traits:\n",
    "    print(f\"\\nDistribution for {trait}:\")\n",
    "    print(Y_aligned[trait].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Modified Functions for Multi-Output\n",
    "#############################################\n",
    "\n",
    "def plot_advanced_confusion_matrix(y_true, y_pred, classes, title):\n",
    "    \"\"\"Enhanced confusion matrix with normalization and counts\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'Normalized Confusion Matrix\\n{title}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Add raw counts to bottom\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "    ax2.set_xticks(ax.get_xticks())\n",
    "    ax2.set_xticklabels([str(int(x)) for x in cm.sum(axis=0)])\n",
    "    ax2.set_xlabel('Total Predictions')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(y_true, y_probs, classes, title):\n",
    "    \"\"\"Multiclass ROC curves with AUC scores\"\"\"\n",
    "    n_classes = len(classes)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true == i, y_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Plot all classes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = cycle(['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC {classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves - {title}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_probabilities(y_probs, classes, title):\n",
    "    \"\"\"Violin plot of class probability distributions\"\"\"\n",
    "    prob_df = pd.DataFrame(y_probs, columns=classes)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.violinplot(data=prob_df, inner=\"quartile\", palette=\"Set3\")\n",
    "    plt.title(f'Class Probability Distributions\\n{title}')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(feature_importances, feature_names, top_n=20, title=\"\"):\n",
    "    \"\"\"Plot feature importance for tree-based models\"\"\"\n",
    "    indices = np.argsort(feature_importances)[-top_n:]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f'Top {top_n} Feature Importances\\n{title}')\n",
    "    plt.barh(range(top_n), feature_importances[indices], align='center')\n",
    "    plt.yticks(range(top_n), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_prediction_errors(y_true, y_pred, classes, title):\n",
    "    \"\"\"Error analysis: which classes are confused with others\"\"\"\n",
    "    error_matrix = confusion_matrix(y_true, y_pred)\n",
    "    np.fill_diagonal(error_matrix, 0)  # Remove correct predictions\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(error_matrix, annot=True, fmt='d', cmap='Reds',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'Prediction Errors\\n{title}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def decode_labels(Y, label_encoders):\n",
    "    \"\"\"Convert numerical labels back to original text labels\"\"\"\n",
    "    decoded = Y.copy()\n",
    "    for trait in Y.columns:\n",
    "        decoded[trait] = label_encoders[trait].inverse_transform(Y[trait])\n",
    "    return decoded\n",
    "\n",
    "# =============================================\n",
    "#  Probability Trustworthiness Functions\n",
    "# =============================================\n",
    "\n",
    "def plot_calibration_curves(y_true, y_proba, classes, title):\n",
    "    \"\"\"Add this after existing plotting functions\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        true_binary = (y_true == i).astype(int)\n",
    "        prob_pos = y_proba[:, i]\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "            true_binary, prob_pos, n_bins=10, strategy='quantile'\n",
    "        )\n",
    "        plt.plot(mean_predicted_value, fraction_of_positives, 's-', \n",
    "                label=f'{class_name}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k:', label='Perfect')\n",
    "    plt.xlabel('Mean Predicted Probability')\n",
    "    plt.ylabel('Fraction of Positive Samples')\n",
    "    plt.title(f'Calibration: {title}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_brier_scores(y_true, y_proba, classes):\n",
    "    \"\"\"Add this with other metric functions\"\"\"\n",
    "    scores = {}\n",
    "    for i, class_name in enumerate(classes):\n",
    "        true_binary = (y_true == i).astype(int)\n",
    "        scores[class_name] = brier_score_loss(true_binary, y_proba[:, i])\n",
    "    return pd.DataFrame.from_dict(scores, orient='index', columns=['Brier Score'])\n",
    "\n",
    "def analyze_prediction_entropy(y_proba, classes):\n",
    "    \"\"\"Enhanced with uncertainty samples identification\"\"\"\n",
    "    entropies = np.array([entropy(probs) for probs in y_proba])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.histplot(entropies, bins=30, kde=True)\n",
    "    \n",
    "    # Add uncertainty thresholds\n",
    "    low_uncertainty = np.log(len(classes)) * 0.3\n",
    "    high_uncertainty = np.log(len(classes)) * 0.7\n",
    "    ax.axvline(x=low_uncertainty, color='g', linestyle='--', label='Low uncertainty')\n",
    "    ax.axvline(x=high_uncertainty, color='r', linestyle='--', label='High uncertainty')\n",
    "    \n",
    "    plt.title('Prediction Entropy Distribution')\n",
    "    plt.xlabel('Entropy (Higher = More Uncertainty)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return indices of uncertain samples\n",
    "    return np.where(entropies > high_uncertainty)[0]\n",
    "\n",
    "def check_probability_consistency(y_proba, y_pred, classes):\n",
    "    \"\"\"Verify predicted class matches highest probability\"\"\"\n",
    "    mismatches = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if not np.isclose(y_proba[i, y_pred[i]], np.max(y_proba[i])):\n",
    "            mismatches += 1\n",
    "    print(f\"\\nProbability consistency: {100*(1-mismatches/len(y_pred)):.2f}% match\")\n",
    "\n",
    "\n",
    "# =============================================\n",
    "#  Model training and evaluation\n",
    "# =============================================\n",
    "\n",
    "def train_and_evaluate_multitrait(X_aligned, Y_aligned, target_traits, label_encoders, feature_names):\n",
    "    # Split data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_aligned, Y_aligned, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('estimator', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "# After model training:\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    Y_pred_test = best_model.predict(X_test)\n",
    "    Y_proba_test = best_model.predict_proba(X_test)\n",
    "\n",
    "    # Early probability check\n",
    "    print(\"\\nSample raw probability outputs:\")\n",
    "    for i, trait in enumerate(target_traits):\n",
    "        print(f\"\\nFirst 5 samples - {trait}:\")\n",
    "        print(pd.DataFrame(Y_proba_test[i][:5], columns=label_encoders[trait].classes_))\n",
    "\n",
    "    \n",
    "    for idx, trait in enumerate(target_traits):\n",
    "        y_proba = Y_proba_test[idx]\n",
    "        y_pred = Y_pred_test[:, idx]\n",
    "    # Probability consistency check:\n",
    "        check_probability_consistency(y_proba, y_pred, label_encoders[trait].classes_)\n",
    "        uncertain_samples = analyze_prediction_entropy(y_proba, label_encoders[trait].classes_)\n",
    "        print(f\"Found {len(uncertain_samples)} highly uncertain predictions for {trait}\")\n",
    "    \n",
    "    # Decode labels\n",
    "    Y_test_decoded = decode_labels(pd.DataFrame(Y_test, columns=target_traits), label_encoders)\n",
    "    Y_pred_decoded = decode_labels(pd.DataFrame(Y_pred_test, columns=target_traits), label_encoders)\n",
    "    \n",
    "    # Per-trait evaluation\n",
    "    for idx, trait in enumerate(target_traits):\n",
    "        classes = label_encoders[trait].classes_\n",
    "        y_true = Y_test_decoded[trait]\n",
    "        y_pred = Y_pred_decoded[trait]\n",
    "        y_proba = Y_proba_test[idx]\n",
    "        \n",
    "        print(f\"\\n{'='*40}\\nEvaluation for {trait}\\n{'='*40}\")\n",
    "        \n",
    "        # 1. Classification Report\n",
    "        print(classification_report(y_true, y_pred, target_names=classes))\n",
    "        \n",
    "        # 2. Advanced Confusion Matrix\n",
    "        plot_advanced_confusion_matrix(y_true, y_pred, classes, trait)\n",
    "        \n",
    "        # 3. ROC Curves (One-vs-Rest)\n",
    "        plot_roc_curves(label_encoders[trait].transform(y_true), y_proba, classes, trait)\n",
    "        \n",
    "        # 4. Class Probability Distributions\n",
    "        plot_class_probabilities(y_proba, classes, trait)\n",
    "        \n",
    "        # 5. Prediction Error Analysis\n",
    "        plot_prediction_errors(y_true, y_pred, classes, trait)\n",
    "\n",
    "        # 6. Calibration Curves\n",
    "        plot_calibration_curves(y_true, y_proba, classes, trait)\n",
    "        \n",
    "        # 7. Brier Scores\n",
    "        brier_scores = calculate_brier_scores(y_true, y_proba, classes)\n",
    "        print(\"Brier Scores (Lower = Better):\")\n",
    "        print(brier_scores)\n",
    "        \n",
    "        # 8. Entropy Analysis\n",
    "        analyze_prediction_entropy(y_proba, classes)\n",
    "        \n",
    "        # 9. Feature Importance (for RandomForest only)\n",
    "        if 'randomforest' in str(best_model.named_steps['estimator'].estimator).lower():\n",
    "            importances = best_model.named_steps['estimator'].estimator.feature_importances_\n",
    "            plot_feature_importance(importances, feature_names, title=trait)\n",
    "    \n",
    "    # Additional Visualizations\n",
    "    plot_calibration_curves(Y_test, Y_proba_test, label_encoders, target_traits)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Run the enhanced pipeline\n",
    "best_model = train_and_evaluate_multitrait(\n",
    "    X_aligned, \n",
    "    Y_aligned, \n",
    "    target_traits, \n",
    "    label_encoders,\n",
    "    feature_names=selector.get_feature_names_out()  # From variance threshold\n",
    ")\n",
    "\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Questions to Answer:\n",
    "### Are probabilities calibrated?\n",
    "→ Check calibration curves & Brier scores\n",
    "\n",
    "### Where is the model uncertain?\n",
    "→ Entropy analysis + probability distributions\n",
    "\n",
    "### Do errors make biological sense?\n",
    "→ Confusion matrices between similar traits (e.g., facultative vs. microaerophilic)\n",
    "\n",
    "### Can we trust high-confidence predictions?\n",
    "→ Reliability diagrams for high-probability bins (>80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KEGG Pathway Mapping\n",
    "def map_ko_to_pathways(ko_terms):\n",
    "    kegg = KEGG()\n",
    "    pathways = {}\n",
    "    for ko in ko_terms:\n",
    "        try:\n",
    "            gene_links = kegg.link(\"pathway\", ko)\n",
    "            if gene_links:\n",
    "                for entry in gene_links.strip().split(\"\\n\"):\n",
    "                    split_entry = entry.split(\"\\t\")\n",
    "                    if len(split_entry) >= 2:\n",
    "                        ko_id, pathway_id = split_entry[0], split_entry[1]\n",
    "                        if pathway_id not in pathways:\n",
    "                            pathways[pathway_id] = set()\n",
    "                        pathways[pathway_id].add(ko)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ko}: {e}\")\n",
    "    return pathways\n",
    "\n",
    "selected_important_features = X_terms.columns[selector.get_support()]\n",
    "pathways = map_ko_to_pathways(selected_important_features)\n",
    "\n",
    "# Creating the adjacency matrix with translated KO terms, including original KO term\n",
    "translated_kos = {ko: f\"Translated_{ko}\" for ko in selected_important_features}  # Placeholder for actual translation function\n",
    "pathway_matrix = pd.DataFrame(\n",
    "    index=[f\"{translated_kos[ko]} ({ko})\" for ko in selected_important_features],\n",
    "    columns=pathways.keys(),\n",
    "    data=0\n",
    ")\n",
    "for pathway, kos in pathways.items():\n",
    "    for ko in kos:\n",
    "        if ko in selected_important_features:\n",
    "            pathway_matrix.loc[f\"{translated_kos[ko]} ({ko})\", pathway] = 1\n",
    "\n",
    "# Fetch and rename pathway names for readability\n",
    "kegg = KEGG()\n",
    "for column in pathway_matrix.columns:\n",
    "    pathway_info = kegg.get(column)\n",
    "    parsed_info = kegg.parse(pathway_info)\n",
    "    pathway_name = parsed_info['NAME'][0] if 'NAME' in parsed_info else column\n",
    "    pathway_matrix.rename(columns={column: pathway_name}, inplace=True)\n",
    "\n",
    "print(\"Pathway matrix after renaming:\\n\", pathway_matrix)\n",
    "\n",
    "# Heatmap visualization\n",
    "sns.heatmap(pathway_matrix, annot=True, cmap=\"Greys\", cbar=False)\n",
    "plt.title(f'Adjacency Matrix of KO Terms and Pathways (Multilabel)')\n",
    "plt.xlabel('Pathways')\n",
    "plt.ylabel('KO Terms')\n",
    "plt.show()\n",
    "\n",
    "# Network Visualization\n",
    "G = nx.Graph()\n",
    "\n",
    "# Define a list of general pathways to exclude\n",
    "excluded_pathways = [\"metabolic pathways\"]  # You can add more general terms here\n",
    "\n",
    "# Add nodes and edges with renamed pathway names\n",
    "for ko in selected_important_features:\n",
    "    translated_label = f\"{translated_kos[ko]} ({ko})\"\n",
    "    G.add_node(ko, title=translated_label, label=translated_label, color='red', size=20)\n",
    "\n",
    "for pathway_id, kos in pathways.items():\n",
    "    pathway_info = kegg.get(pathway_id)\n",
    "    parsed_info = kegg.parse(pathway_info)\n",
    "    pathway_name = parsed_info['NAME'][0] if 'NAME' in parsed_info else pathway_id\n",
    "    if pathway_name.lower() not in excluded_pathways:\n",
    "        G.add_node(pathway_name, title=pathway_name, label=pathway_name, color='blue', size=30)\n",
    "        for ko in kos:\n",
    "            G.add_edge(ko, pathway_name)\n",
    "\n",
    "# Pyvis network visualization\n",
    "nt = Network(\"800px\", \"1200px\", notebook=True, heading=f'Interactive Network of KO Terms and Pathways (Multilabel)', bgcolor=\"#ffffff\", font_color=\"black\", cdn_resources='remote')\n",
    "nt.from_nx(G)\n",
    "nt.toggle_physics(True)\n",
    "nt.show_buttons(filter_=['physics'])\n",
    "nt.save_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
